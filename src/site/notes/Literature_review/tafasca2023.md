---
{"dg-publish":true,"permalink":"/literature-review/tafasca2023/","title":"ChildPlay A New Benchmark for Understanding Children's Gaze Behaviour","tags":["Computer","Science","-","Computer","Vision","and","Pattern","Recognition","EyeTracking"]}
---


## ChildPlay: A New Benchmark for Understanding Children's Gaze Behaviour

> [!Cite]
> Tafasca, S., Gupta, A., & Odobez, J.-M. (2023). _ChildPlay: A New Benchmark for Understanding Childrenâ€™s Gaze Behaviour_ (No. arXiv:2307.01630). arXiv. [https://doi.org/10.48550/arXiv.2307.01630](https://doi.org/10.48550/arXiv.2307.01630)


>[!md]
> **Year**:: 2023   
> **Citekey**:: tafasca2023  
> **itemType**:: preprint  
> **DOI**:: 10.48550/arXiv.2307.01630    

> [!LINK] 
> [2023_Tafasca et al._ChildPlay A New Benchmark for Understanding Children's Gaze Behaviour.pdf](zotero://select/library/items/4UML8KFS)

> [!Abstract]
>
> Gaze behaviors such as eye-contact or shared attention are important markers for diagnosing developmental disorders in children. While previous studies have looked at some of these elements, the analysis is usually performed on private datasets and is restricted to lab settings. Furthermore, all publicly available gaze target prediction benchmarks mostly contain instances of adults, which makes models trained on them less applicable to scenarios with young children. In this paper, we propose the first study for predicting the gaze target of children and interacting adults. To this end, we introduce the ChildPlay dataset: a curated collection of short video clips featuring children playing and interacting with adults in uncontrolled environments (e.g. kindergarten, therapy centers, preschools etc.), which we annotate with rich gaze information. We further propose a new model for gaze target prediction that is geometrically grounded by explicitly identifying the scene parts in the 3D field of view (3DFoV) of the person, leveraging recent geometry preserving depth inference methods. Our model achieves state of the art results on benchmark datasets and ChildPlay. Furthermore, results show that looking at faces prediction performance on children is much worse than on adults, and can be significantly improved by fine-tuning models using child gaze annotations. Our dataset and models will be made publicly available.
>.
> 


## Notes

| File                                                               | file.name          |
| ------------------------------------------------------------------ | ------------------ |
| [[NotesConnectToPapers/tafasca2023a_notes\|tafasca2023a_notes]] | tafasca2023a_notes |
| [[NotesConnectToPapers/tafasca2023_notes\|tafasca2023_notes]]   | tafasca2023_notes  |

{ .block-language-dataview}

[[NotesConnectToPapers/tafasca2023_notes\|tafasca2023_notes]]

## Figures

**Imported: 2025-02-12**

> ![Images/tafasca2023/image-undefined-x303-y455.png](/img/user/Images/tafasca2023/image-undefined-x303-y455.png)

> ![Images/tafasca2023/image-undefined-x303-y359.png](/img/user/Images/tafasca2023/image-undefined-x303-y359.png)

> ![Images/tafasca2023/image-3-x303-y568.png](/img/user/Images/tafasca2023/image-3-x303-y568.png)

> ![Images/tafasca2023/image-5-x44-y448.png](/img/user/Images/tafasca2023/image-5-x44-y448.png)

> ![Images/tafasca2023/image-5-x44-y282.png](/img/user/Images/tafasca2023/image-5-x44-y282.png)

> ![Images/tafasca2023/image-6-x42-y451.png](/img/user/Images/tafasca2023/image-6-x42-y451.png)

> ![Images/tafasca2023/image-7-x306-y649.png](/img/user/Images/tafasca2023/image-7-x306-y649.png)

> ![Images/tafasca2023/image-8-x46-y603.png](/img/user/Images/tafasca2023/image-8-x46-y603.png)

> ![Images/tafasca2023/image-8-x45-y277.png](/img/user/Images/tafasca2023/image-8-x45-y277.png)
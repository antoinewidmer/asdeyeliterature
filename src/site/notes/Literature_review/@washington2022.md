---
{"dg-publish":true,"permalink":"/literature-review/washington2022/","title":"Crowd annotations can approximate clinical autism impressions from short home videos with privacy protections","tags":["autism"]}
---


## Crowd annotations can approximate clinical autism impressions from short home videos with privacy protections

> [!Cite]
> Washington, P., Chrisman, B., Leblanc, E., Dunlap, K., Kline, A., Mutlu, C., Stockham, N., Paskov, K., & Wall, D. P. (2022). Crowd annotations can approximate clinical autism impressions from short home videos with privacy protections. _Intelligence-Based Medicine_, _6_, 100056. [https://doi.org/10.1016/j.ibmed.2022.100056](https://doi.org/10.1016/j.ibmed.2022.100056)


>[!md]
> **Year**:: 2022   
> **Citekey**:: washington2022  
> **itemType**:: journalArticle  
> **Journal**:: *Intelligence-Based Medicine*  
> **Volume**:: 6   
> **Pages**:: 100056  
> **DOI**:: 10.1016/j.ibmed.2022.100056    

> [!LINK] 
> [2022_Washington et al._Crowd annotations can approximate clinical autism impressions from short home videos with privacy pr.pdf](zotero://select/library/items/Z7R355YA)

> [!Abstract]
>
> Artificial Intelligence (A.I.) solutions are increasingly considered for telemedicine. For these methods to serve children and their families in home settings, it is crucial to ensure the privacy of the child and parent or caregiver. To address this challenge, we explore the potential for global image transformations to provide privacy while preserving the quality of behavioral annotations. Crowd workers have previously been shown to reliably annotate behavioral features in unstructured home videos, allowing machine learning classifiers to detect autism using the annotations as input. We evaluate this method with videos altered via pixelation, dense optical flow, and Gaussian blurring. On a balanced test set of 30 videos of children with autism and 30 neurotypical controls, we find that the visual privacy alterations do not drastically alter any individual behavioral annotation at the item level. The AUROC on the evaluation set was 90.0% Â±7.5% for unaltered videos, 85.0% Â±9.0% for pixelation, 85.0% Â±9.0% for optical flow, and 83.3% Â±9.3% for blurring, demonstrating that an aggregation of small changes across behavioral questions can collectively result in increased misdiagnosis rates. We also compare crowd answers against clinicians who provided the same annotations for the same videos as crowd workers, and we find that clinicians have higher sensitivity in their recognition of autism-related symptoms. We also find that there is a linear correlation (rÂ =Â 0.75, pÂ <Â 0.0001) between the mean Clinical Global Impression (CGI) score provided by professional clinicians and the corresponding score emitted by a previously validated autism classifier with crowd inputs, indicating that the classifier's output probability is a reliable estimate of the clinical impression of autism. A significant correlation is maintained with privacy alterations, indicating that crowd annotations can approximate clinician-provided autism impression from home videos in a privacy-preserved manner.
>.
> 

## ğŸ“Œ Summary


## ğŸ”¬ Methods 

### Study Design

### Participants

### Tasks for participants

### System setup and hardware

### Data Analysis

## ğŸ“Š Results & Key Findings 


## ğŸ” Related Work 



## ğŸ“ Observations

### Strengths of the Study

### Major Concerns and Challenges